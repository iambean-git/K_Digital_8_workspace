{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYJeA4fpcGNk"
      },
      "source": [
        "# Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AZqhmeccW7p"
      },
      "source": [
        "\n",
        "## 1. 미국 대통령에 관한 정보를 담은 파일을 읽고 이를 처리하는 프로그램을 작성하세요. 그로버 클리블랜드처럼 비연속적인 임기를 지낸 대통령들은 각각의 임기가 따로 나열되어 있습니다.\n",
        "\n",
        "* President 클래스를 작성하고, 대통령의 이름, 각 임기의 시작 및 종료 연도를 추출하는 메서드를 작성하세요. 또한, 대통령이 총 4년 이상을 재임했는지(연속적이든 아니든)를 확인하는 메서드를 작성하세요.\n",
        "\n",
        "* 현재 재임 중인 대통령(예: 조 바이든, 종료 연도가 없는 경우)의 처리를 포함해야 합니다.\n",
        "\n",
        "* 파일: https://github.com/dbwebb-se/vlinux/blob/master/example/grep/presidents.txt\n",
        "\n",
        "* 파일의 각 줄에는 대통령의 이름과 그들이 재임한 연도가 쉼표로 구분되어 나열되어 있습니다.\n",
        "\n",
        "### President 클래스\n",
        "\n",
        "* 생성자 (__init__): President 객체를 초기화하며 대통령의 이름을 저장하고 __process_term 메서드를 사용하여 각 임기를 처리합니다. 임기의 목록은 문자열로 전달되며, 각 문자열은 \"1789-1797\" 또는 \"1885-1889, 1893-1897\"처럼 표현됩니다.\n",
        "\n",
        "> 힌트: 생성자에서 각 임기 문자열을 __process_term 메서드를 사용해 (start_year, end_year) 튜플로 변환하세요. 이렇게 하면 대통령의 임기 데이터를 쉽게 접근하고 조작할 수 있습니다.\n",
        "\n",
        "* __process_term 메서드: 대통령 임기를 나타내는 문자열(예: \"1789-1797\")을 받아 시작 및 종료 연도를 정수로 변환하는 튜플로 바꿉니다. 종료 연도가 없으면(예: 현재 대통령인 경우) 현재 연도를 할당합니다.\n",
        "\n",
        "> 힌트: 문자열 분할(term.split('-'))을 사용해 임기를 시작 연도와 종료 연도로 나누세요. 종료 연도가 없으면 datetime.now().year를 사용하여 현재 연도를 할당하세요. 이 메서드는 완료된 임기와 진행 중인 임기 모두를 처리할 수 있도록 합니다.\n",
        "\n",
        "* is_served_multiple 메서드: 대통령이 총 4년 이상 재임했는지 또는 여러 임기를 지냈는지 확인합니다. 모든 임기를 합산하여 총 재임 기간이 4년을 초과하는지 확인합니다.\n",
        "\n",
        "> 힌트: 각 임기의 종료 연도와 시작 연도 사이의 차이를 합산하여 총 재임 기간을 계산하세요.\n",
        "\n",
        "### 함수\n",
        "\n",
        "read_presidents_from_file 함수: 파일에서 각 줄에 대통령의 이름과 재임 기간이 포함된 데이터를 읽고, President 객체의 목록을 생성합니다.\n",
        "\n",
        "> 힌트: split(', ', 1)을 사용해 이름과 임기를 분리하세요. 그런 다음 임기를 목록으로 나누고 President 생성자에 전달하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU5GRliRe3Gx"
      },
      "outputs": [],
      "source": [
        "#파일 존재 및 내용확인\n",
        "file_content = open('./presidents.txt')\n",
        "for line in file_content:\n",
        "  print(line.rstrip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNYIQCYnt9ca"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "class President:\n",
        "    def __init__(self, name: str, terms: list):\n",
        "        self.name = name\n",
        "        self.terms = self.__process_term(terms)\n",
        "\n",
        "    def __process_term(self, term: str):\n",
        "        start, end = term.split(\"-\")\n",
        "        if end == \"\" : end=datetime.now().year\n",
        "        return int(start), int(end)\n",
        "\n",
        "    def is_served_multiple(self) -> bool:\n",
        "        if self.terms[1]-self.terms[0] > 4 : return True\n",
        "        else : return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WchTnVn0eCIh"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def read_presidents_from_file(file_path: str) -> list:\n",
        "    presidentList = []\n",
        "    path = Path(file_path)\n",
        "    contents = path.read_text().rstrip().splitlines()\n",
        "    for content in contents :\n",
        "      name, term = content.split(\", \",1)\n",
        "      presidentList.append(President(name, term))\n",
        "    return presidentList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19HbTZd5XI4i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "presidents = read_presidents_from_file('./presidents.txt')\n",
        "\n",
        "count = 0\n",
        "for president in presidents:\n",
        "    if president.is_served_multiple():\n",
        "        count += 1\n",
        "\n",
        "assert count == 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGbPfQJEc5pl"
      },
      "source": [
        "\n",
        "## 2. TextAnalyzer 클래스를 작성하세요. 이 클래스에는 word_frequency() 메서드가 있으며, 생성 시 제공되는 텍스트 파일을 읽고 파일에 있는 각 단어의 빈도를 반환합니다. 단어는 소문자로 변환되어야 하고, 구두점은 무시되어야 합니다. 파일을 찾지 못했을 경우의 예외 처리를 적절히 처리하세요.\n",
        "\n",
        "> 파일 URL: https://gist.github.com/phillipj/4944029\n",
        "\n",
        "\n",
        "# 클래스 TextAnalyzer\n",
        "\n",
        "* 생성자 (init): TextAnalyzer 클래스의 인스턴스를 초기화합니다. 이 생성자는 하나의 인자 file_path를 받으며, 이 인자는 분석할 텍스트 파일의 경로를 나타냅니다. 이 인자는 나중에 다른 메서드에서 사용될 수 있도록 인스턴스 변수로 저장됩니다.\n",
        "\n",
        "> 힌트: 클래스를 인스턴스화할 때, 유효한 파일 경로를 생성자에게 인자로 전달하는지 확인하세요. 이 파일 경로는 word_frequency 메서드에서 사용됩니다.\n",
        "\n",
        "* word_frequency(self): 텍스트 파일을 처리하여 파일 내의 각 단어를 빈도로 매핑하는 딕셔너리를 반환합니다. 이 메서드는 파일의 내용을 읽고, 모든 텍스트를 소문자로 변환하여 대소문자 구분 없는 비교를 보장하며, 구두점을 제거하여 실제 단어에 집중합니다. 그런 다음, 내용을 단어로 분리하고, 각 단어의 출현 빈도를 계산하여 딕셔너리에 저장합니다.\n",
        "\n",
        "> 힌트: 이 메서드는 파일을 읽고 분석하여 각 단어가 몇 번 등장했는지를 카운팅하는 역할을 합니다. 텍스트는 대소문자 구분 없이 처리되어야 하며, 구두점과 같은 불필요한 문자는 제거되어야 합니다. 메서드는 각 단어와 그에 해당하는 빈도를 포함하는 딕셔너리를 반환합니다. 또한, 파일이 존재하지 않을 경우를 처리하는 예외처리도 해야 합니다.\n",
        "\n",
        "> 구두점 제거\n",
        "```python\n",
        "words = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in file_content]).split()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OXPr0YxXJwx"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "class TextAnalyzer:\n",
        "    def __init__(self, file_path: str):\n",
        "        self.file_path = file_path\n",
        "\n",
        "    def word_frequency(self) -> dict:\n",
        "      path = Path(self.file_path)\n",
        "      try :\n",
        "        dic_words = {}\n",
        "        contents = path.read_text().lower()\n",
        "        words = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in contents]).split()\n",
        "        for word in words :\n",
        "          if word not in dic_words.keys():\n",
        "            dic_words[word] = 1\n",
        "          else :\n",
        "            dic_words[word] += 1\n",
        "\n",
        "      except :\n",
        "        print(\"해당 파일이 존재하지 않습니다\")\n",
        "        dic_words = None\n",
        "\n",
        "      finally :\n",
        "        return dic_words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TEvUJffty7_",
        "outputId": "4ccffac7-8444-4c16-8cdd-6a026677ea6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'hello': 2, 'alice': 1, 'text': 1, 'bin': 1, 'python': 2}"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TextAnalyzer(\"test.txt\").word_frequency()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trMw_2Fdh97P",
        "outputId": "dbad4aa6-8801-4b7a-d8b9-0ab2254a145b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "해당 파일이 존재하지 않습니다\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "def read_expected_result(expected_result_file):\n",
        "  try:\n",
        "      with open(expected_result_file, 'rb') as f:\n",
        "          expected_result = pickle.load(f)\n",
        "  except FileNotFoundError:\n",
        "      print(\"Expected result file not found.\")\n",
        "      expected_result = None\n",
        "  finally:\n",
        "      return expected_result\n",
        "\n",
        "input_file_path = \"alice_in_wonderland.txt\"\n",
        "expected_result_file = \"expected_result.pkl\"\n",
        "\n",
        "analyzer = TextAnalyzer(input_file_path)\n",
        "result = analyzer.word_frequency()\n",
        "\n",
        "expected_result = read_expected_result(expected_result_file)\n",
        "sorted_result = sorted(result.items(), key=lambda x: (-x[1], x[0]))\n",
        "assert sorted_result == expected_result\n",
        "\n",
        "\n",
        "\n",
        "##예외처리 확인하기 (CHECK IT!!!)\n",
        "missing_file_path = \"missing.txt\"\n",
        "expected_result_file = \"missing_output.pkl\"\n",
        "analyzer = TextAnalyzer(missing_file_path)\n",
        "\n",
        "#expected_result = read_expected_result(expected_result_file)\n",
        "output = analyzer.word_frequency()\n",
        "\n",
        "#assert output == expected_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INqFk2K5c7ks"
      },
      "source": [
        "## 3. 다음을 계산하는 메서드를 포함한 CountryStatistics 클래스를 작성하세요:\n",
        "\n",
        "* GDP가 가장 높은 상위 5개 국가: 이 메서드는 GDP가 가장 높은 상위 5개 국가의 이름을 반환하며, GDP 값은 쉼표로 형식화됩니다.\n",
        "* 기대 수명이 가장 긴 상위 5개 국가: 이 메서드는 기대 수명이 가장 긴 상위 5개 국가의 이름을 반환합니다.\n",
        "* 인구 밀도가 가장 높은 상위 5개 국가: 이 메서드는 인구 밀도가 가장 높은 상위 5개 국가의 이름을 반환합니다.\n",
        "\n",
        "* 파일: https://gist.github.com/vr-23/d6a4a0aadcf3a2640091ca43c25e1955#file-world-data-2023-csv\n",
        "\n",
        "### CountryStatistics 클래스\n",
        "\n",
        "* __clean_numeric_data(value: str): 문자열을 입력으로 받아 쉼표, 달러 기호, 백분율 기호를 제거하고 숫자 값을 float으로 반환합니다. 입력을 변환할 수 없으면 0.0을 반환합니다.\n",
        "\n",
        "> 힌트: 이 함수는 쉼표나 달러 기호가 포함된 CSV 파일의 숫자 데이터를 처리하는 데 유용합니다.\n",
        "빈 문자열이나 숫자가 아닌 값을 처리할 수 있도록 예외 처리에 신경 쓰세요.\n",
        "\n",
        "* __load_data(filename: str): CSV 파일에서 국가 데이터를 로드하고 데이터를 파싱하여 Country 객체를 생성합니다. 정리된 데이터는 self.countries 리스트에 저장됩니다.\n",
        "\n",
        "> 힌트: csv.reader를 사용하여 CSV 파일을 한 줄씩 읽습니다.\n",
        "첫 번째 행은 헤더이므로 건너뜁니다.\n",
        "모든 숫자 데이터 필드에 대해 __clean_numeric_data를 호출하여 데이터를 저장하기 전에 정확하게 정리된 데이터를 확인하세요.\n",
        "GDP, 기대 수명, 인구 등의 열 인덱스를 정확하게 매핑하세요.\n",
        "\n",
        "* top_5_gdp(): GDP가 가장 높은 상위 5개 국가의 이름과 쉼표로 형식화된 GDP 값을 포함한 튜플 목록을 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 gdp 속성 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 선택하세요.\n",
        "국가 이름과 형식화된 GDP 값을 반환하세요.\n",
        "\n",
        "* top_5_life_expectancy(): 기대 수명이 가장 긴 상위 5개 국가의 이름과 그들의 기대 수명 값을 포함한 튜플 목록을 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 기대 수명(life_expectancy) 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 추출하세요.\n",
        "기대 수명 값은 형식화할 필요가 없으므로 있는 그대로 반환하세요.\n",
        "\n",
        "* countries_by_density(): 인구 밀도가 가장 높은 상위 5개 국가의 이름과 인구 밀도를 반환합니다.\n",
        "\n",
        "> 힌트: 국가들을 인구 밀도(density) 속성 기준으로 내림차순 정렬하세요.\n",
        "슬라이싱 ([:5])을 사용하여 상위 5개 항목을 선택하세요.\n",
        "인구 밀도 값은 정수이므로 형식화할 필요가 없습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rROlXGTH_Hxk",
        "outputId": "6d71082f-5a39-423d-a298-c660d3e08a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_csv.reader object at 0x7ef462fefd10>\n",
            "['Country', 'Density (P/Km2)', 'Abbreviation', 'Agricultural Land( %)', 'Land Area(Km2)', 'Armed Forces size', 'Birth Rate', 'Calling Code', 'Capital/Major City', 'Co2-Emissions', 'CPI', 'CPI Change (%)', 'Currency-Code', 'Fertility Rate', 'Forested Area (%)', 'Gasoline Price', 'GDP', 'Gross primary education enrollment (%)', 'Gross tertiary education enrollment (%)', 'Infant mortality', 'Largest city', 'Life expectancy', 'Maternal mortality ratio', 'Minimum wage', 'Official language', 'Out of pocket health expenditure', 'Physicians per thousand', 'Population', 'Population: Labor force participation (%)', 'Tax revenue (%)', 'Total tax rate', 'Unemployment rate', 'Urban_population', 'Latitude', 'Longitude']\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "f = open('./countries.csv','r')\n",
        "rdr = csv.reader(f)\n",
        "# words = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in rdr]).split()\n",
        "print (rdr)\n",
        "print(list(rdr)[0])\n",
        "for line in rdr:\n",
        "   print(line)\n",
        "\n",
        "\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H7tIl76OAOFl"
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'cp949' codec can't decode byte 0xbd in position 6524: illegal multibyte sequence",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountries.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplitlines()   \u001b[38;5;66;03m#모든 행을 리스트로 반환해 라인에 할당\u001b[39;00m\n\u001b[0;32m      9\u001b[0m reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(lines)\n\u001b[0;32m     10\u001b[0m header_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(reader)\n",
            "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1028\u001b[0m, in \u001b[0;36mPath.read_text\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m   1026\u001b[0m encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m-> 1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0xbd in position 6524: illegal multibyte sequence"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path(\"countries.csv\")\n",
        "\n",
        "\n",
        "lines = path.read_text().splitlines()   #모든 행을 리스트로 반환해 라인에 할당\n",
        "\n",
        "reader = csv.reader(lines)\n",
        "header_row = next(reader)\n",
        "\n",
        "for index, column_header in enumerate(header_row):\n",
        "    print(index, column_header)\n",
        "\n",
        "\n",
        "\n",
        "# path = Path('the_csv_file_format/partial_programs/weather_data/sitka_weather_07-2021_simple.csv')\n",
        "# lines = path.read_text().splitlines()   #모든 행을 리스트로 반환해 라인에 할당\n",
        "\n",
        "# reader = csv.reader(lines)\n",
        "# header_row = next(reader)\n",
        "\n",
        "# for index, column_header in enumerate(header_row):\n",
        "#     print(index, column_header)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u-O90MGn4Hmy"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "class Country:\n",
        "    def __init__(self, name: str, density: int, land_area: int, gdp: float, life_expectancy: float, population: int):\n",
        "        self.name = name\n",
        "        self.density = density\n",
        "        self.land_area = land_area\n",
        "        self.gdp = gdp\n",
        "        self.life_expectancy = life_expectancy\n",
        "        self.population = population\n",
        "\n",
        "class CountryStatistics:\n",
        "    def __init__(self, filename: str):\n",
        "        self.filename = filename\n",
        "        self.countries = []\n",
        "        self.__load_data(self.filename)\n",
        "\n",
        "    def __clean_numeric_data(self, value: str) -> float:\n",
        "      f_value = 0.0\n",
        "      str_value = ''.join([char if char.isalnum() or char.isspace() else ' ' for char in value])\n",
        "      if str_value==\"\" : return f_value\n",
        "      else:\n",
        "        try:\n",
        "          f_value = float(str_value)\n",
        "        except:\n",
        "          f_value = 0.0\n",
        "        finally :\n",
        "          return f_value\n",
        "\n",
        "    def __load_data(self, filename: str):\n",
        "      path = Path(self.filename)\n",
        "\n",
        "      lines = self.path.read_text().splitlines()\n",
        "      reader = csv.reader(lines)\n",
        "      header_row = next(reader)  # 헤더 행 건너뛰기\n",
        "\n",
        "      for row in reader :\n",
        "        name =\n",
        "        density =\n",
        "\n",
        "      pass\n",
        "\n",
        "    def top_5_gdp(self):\n",
        "        pass\n",
        "\n",
        "    def top_5_life_expectancy(self):\n",
        "        pass\n",
        "\n",
        "    def countries_by_density(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "AkzKVN42qeBp",
        "outputId": "49531330-795e-47fb-8eab-01cbf389fcc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Country', 'Density (P/Km2)', 'Abbreviation', 'Agricultural Land( %)', 'Land Area(Km2)', 'Armed Forces size', 'Birth Rate', 'Calling Code', 'Capital/Major City', 'Co2-Emissions', 'CPI', 'CPI Change (%)', 'Currency-Code', 'Fertility Rate', 'Forested Area (%)', 'Gasoline Price', 'GDP', 'Gross primary education enrollment (%)', 'Gross tertiary education enrollment (%)', 'Infant mortality', 'Largest city', 'Life expectancy', 'Maternal mortality ratio', 'Minimum wage', 'Official language', 'Out of pocket health expenditure', 'Physicians per thousand', 'Population', 'Population: Labor force participation (%)', 'Tax revenue (%)', 'Total tax rate', 'Unemployment rate', 'Urban_population', 'Latitude', 'Longitude']\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'builtin_function_or_method' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-4b4f0f9a2a75>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCountryStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"countries.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-154-8cd5275ce749>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__clean_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-154-8cd5275ce749>\u001b[0m in \u001b[0;36m__load_data\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# index_list = [\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#     cl[0].index['Country'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "CountryStatistics(\"./api_file_io/countries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtu5YK_Vx623"
      },
      "outputs": [],
      "source": [
        "expected_gdp_output = [\n",
        "    (\"United States\", \"21,427,700,000,000\"),\n",
        "    (\"China\", \"19,910,000,000,000\"),\n",
        "    (\"Japan\", \"5,081,769,542,380\"),\n",
        "    (\"Germany\", \"3,845,630,030,824\"),\n",
        "    (\"United Kingdom\", \"2,827,113,184,696\")\n",
        "]\n",
        "\n",
        "expected_life_expectancy_output = [\n",
        "    (\"San Marino\", 85.4),\n",
        "    (\"Japan\", 84.2),\n",
        "    (\"Switzerland\", 83.6),\n",
        "    (\"Spain\", 83.3),\n",
        "    (\"Singapore\", 83.1)\n",
        "]\n",
        "\n",
        "expected_density_output = [\n",
        "    (\"Monaco\", 26337),\n",
        "    (\"Singapore\", 8358),\n",
        "    (\"Bahrain\", 2239),\n",
        "    (\"Vatican City\", 2003),\n",
        "    (\"Maldives\", 1802)\n",
        "]\n",
        "\n",
        "expected_average_population = 57\n",
        "\n",
        "stats = CountryStatistics('./countries.csv')\n",
        "\n",
        "for (expected_country, expected_gdp), (result_country, result_gdp) in zip(expected_gdp_output, stats.top_5_gdp()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_gdp == result_gdp\n",
        "\n",
        "for (expected_country, expected_life), (result_country, result_life) in zip(expected_life_expectancy_output, stats.top_5_life_expectancy()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_life == result_life\n",
        "\n",
        "for (expected_country, expected_density), (result_country, result_density) in zip(expected_density_output, stats.countries_by_density()):\n",
        "    assert expected_country == result_country\n",
        "    assert expected_density == result_density\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtGlz5V2Nhmw"
      },
      "source": [
        "## 4. 파일에서 숫자 데이터를 처리하고 합계, 평균, 최소값, 최대값 및 중앙값과 같은 기본 통계를 계산하는 메서드를 제공하는 FileProcessor 클래스를 작성하세요.\n",
        "\n",
        "### FileProcessor 클래스\n",
        "\n",
        "* 생성자: FileProcessor 객체를 초기화합니다. 파일 이름을 입력으로 받아 저장하고, 이후에 파일에서 읽어온 숫자 데이터를 저장할 빈 리스트 self.data를 초기화합니다.\n",
        "\n",
        "> 힌트: 이 메서드는 파일을 읽고 처리할 준비를 합니다. 파일 경로는 저장되지만, 데이터는 다른 메서드에서 요청할 때까지 로드되지 않습니다.\n",
        "\n",
        "* __read_file(self): 파일에서 데이터를 읽습니다. 파일을 읽기 모드로 열고, 각 줄에서 불필요한 문자를 제거한 후 데이터를 실수로 변환합니다. 이 처리된 데이터를 self.data에 저장합니다.\n",
        "\n",
        "> 힌트: 이 메서드를 사용하여 필요한 경우에만 데이터를 지연 로드합니다. FileNotFoundError 및 ValueError와 같은 파일 관련 오류를 처리하여 파일 읽기가 견고하게 이루어지도록 합니다.\n",
        "\n",
        "* calc_sum(self): 숫자 데이터의 합계를 계산합니다. 데이터가 아직 읽히지 않았다면 먼저 _read_file 메서드를 호출합니다. 데이터가 사용 가능해지면 값을 합산하고 결과를 소수점 한 자리까지 반올림하여 반환합니다.\n",
        "\n",
        "> 힌트: 계산을 수행하기 전에 파일이 읽혔는지 확인하세요. 내장된 sum() 함수를 사용하여 코드를 간소화할 수 있습니다. 빈 파일이 있을 수 있으므로 _read_file이 성공적으로 호출된 경우에만 이 메서드가 제대로 작동합니다.\n",
        "\n",
        "* calc_average(self): 숫자 데이터의 평균(산술 평균)을 계산합니다. 필요한 경우 _read_file을 호출하여 데이터가 사용 가능한지 확인합니다. 데이터가 없을 경우 ZeroDivisionError를 발생시킵니다.\n",
        "\n",
        "> 힌트: 평균은 데이터의 합계를 항목 수로 나눈 값입니다. 나누기를 수행하기 전에 항목이 있는지 확인하여 0으로 나누는 오류를 방지하세요.\n",
        "\n",
        "* calc_min(self): 데이터셋에서 최소값을 계산하고 반환합니다. 아직 파일을 읽지 않았다면 파일을 읽어 데이터를 확인합니다. 데이터가 없을 경우 ValueError를 발생시킵니다.\n",
        "\n",
        "> 힌트: Python의 내장 min() 함수를 사용하여 최소값을 찾습니다. 데이터가 없는 경우 적절하게 예외를 발생시켜야 합니다.\n",
        "\n",
        "* calc_max(self): 데이터셋에서 최대값을 계산하고 반환합니다. 필요한 경우 데이터를 읽고, 데이터가 비어 있으면 ValueError를 발생시킵니다.\n",
        "\n",
        "> 힌트: calc_min()과 유사하게 구현되지만, max()를 사용하여 가장 큰 숫자를 반환합니다.\n",
        "\n",
        "* calc_median(self): 숫자 데이터의 중앙값을 계산하고 반환합니다. 데이터를 정렬한 후 중앙값을 계산합니다. 데이터 포인트 수가 홀수인 경우 중간값을 반환하고, 짝수인 경우 두 중간값의 평균을 반환합니다.\n",
        "\n",
        "> 힌트: 데이터를 읽은 후 정렬하여 중앙값을 계산합니다. 데이터 길이가 짝수일 경우 중앙값은 두 중간 숫자의 평균이고, 홀수일 경우 중앙값은 중간 숫자입니다.\n",
        "\n",
        "### 오류 처리\n",
        "\n",
        "클래스는 파일을 찾을 수 없거나 파일에 유효하지 않은 데이터가 있을 때 적절한 예외를 발생시켜야 합니다.\n",
        "\n",
        "* FileNotFoundError: 파일이 존재하지 않을 때 발생합니다.\n",
        "* ValueError: 파일의 한 줄이 실수로 변환할 수 없거나 최소값, 최대값 또는 중앙값 작업에 대해 빈 파일이 제공될 때 발생합니다.\n",
        "* ZeroDivisionError: 파일이 비어 있어 평균을 계산할 데이터가 없을 때 발생합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UAF4rYtNqtF"
      },
      "outputs": [],
      "source": [
        "class FileProcessor:\n",
        "    def __init__(self, file_name: str):\n",
        "        pass\n",
        "\n",
        "    def __read_file(self):\n",
        "        pass\n",
        "\n",
        "    def calc_sum(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_average(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_min(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_max(self) -> float:\n",
        "        pass\n",
        "\n",
        "    def calc_median(self) -> float:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HB7gKAQOZs4"
      },
      "outputs": [],
      "source": [
        "input_files = ['./Numbers.txt', './EmptyFile.txt', './InvalidFile.txt']\n",
        "expected_sums = [23759.0, None, None]\n",
        "expected_averages = [475.2, None, None]\n",
        "expected_mins = [33.0, None, None]\n",
        "expected_maxs = [948.0, None, None]\n",
        "expected_medians = [442.5, None, None]\n",
        "\n",
        "failed_tests = []\n",
        "\n",
        "for file, expected_sum, expected_avg, expected_min, expected_max, expected_median in zip(input_files, expected_sums, expected_averages, expected_mins, expected_maxs, expected_medians):\n",
        "    processor = FileProcessor(file)\n",
        "\n",
        "    try:\n",
        "        result_sum = processor.calc_sum()\n",
        "        if expected_sum is not None:\n",
        "            assert round(result_sum, 1) == round(expected_sum, 1)\n",
        "    except (FileNotFoundError, ValueError, ZeroDivisionError) as e:\n",
        "        if expected_sum is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Sum test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_avg = processor.calc_average()\n",
        "        if expected_avg is not None:\n",
        "            assert round(result_avg, 1) == round(expected_avg, 1)\n",
        "    except (FileNotFoundError, ValueError, ZeroDivisionError) as e:\n",
        "        if expected_avg is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Average test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_min = processor.calc_min()\n",
        "        if expected_min is not None:\n",
        "            assert round(result_min, 1) == round(expected_min, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_min is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Min test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_max = processor.calc_max()\n",
        "        if expected_max is not None:\n",
        "            assert round(result_max, 1) == round(expected_max, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_max is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Max test failed for {file}: {e}\")\n",
        "\n",
        "    try:\n",
        "        result_median = processor.calc_median()\n",
        "        if expected_median is not None:\n",
        "            assert round(result_median, 1) == round(expected_median, 1)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        if expected_median is None:\n",
        "            pass\n",
        "        else:\n",
        "            failed_tests.append(f\"Median test failed for {file}: {e}\")\n",
        "\n",
        "if failed_tests:\n",
        "    for test in failed_tests:\n",
        "        print(test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
